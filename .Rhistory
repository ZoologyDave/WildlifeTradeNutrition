size = guide_legend(title.position="top", title.hjust = 0.5))
p2
# Saving
ggsave("Figs/Bubble Plot Colour 2 12June2020.pdf",
width = 10, height = 6, units = 'in')
rm(list = ls())
woods.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database 17December2019.csv", stringsAsFactors = FALSE)
milk.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database milk only 12February2020.csv", stringsAsFactors = FALSE)
elfs.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/ELFS Study 1 dataset_unbranded_V10.csv", stringsAsFactors = FALSE)
# List of products in woods
products.keep <-
rbind(woods.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
milk.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
elfs.dat %>% dplyr::select(Department, Aisle, Shelf, product_name = Product)) %>%
unique(.)
dat <-
dat %>%
filter(product_name %in% products.keep$product_name)
#######
# General purpose of this code is to
# (a) identify individual ingredients within the food products captured by food db
# (b) identify percent composition of the ingredients that have these listed on back of pack labeling
# (c) categorize these ingredients into ~40 categories that pair with Joseph Poore's LCA database
# (d) Repeat part (c) for product names in case products do no have any listed ingredients, or do not have any ingredients with listed % composition
# (e) Merge with LCA database
# (f) Interpolate % composition for ingredients that do not have a % composition listed
# (g) Estimate total impacts per 100g
#######
###
# Loading functions
source("/Volumes/Citadel/Oxford/Research Projects/Categorizations for Marco/Scripts/Functions File Estimating Env Impact of Food Products 7May2020.R")
###
# Importing libraries
library(plyr)
library(dplyr)
library(readr)
library(stringr)
library(stringi)
library(reshape2)
library(dismo)
#####
###
# Importing and managing the data set
dat <-
read_csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/product_data.csv")
# Limiting to products for which I have food categories
# Adding in Woods Data
woods.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database 17December2019.csv", stringsAsFactors = FALSE)
milk.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database milk only 12February2020.csv", stringsAsFactors = FALSE)
elfs.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/ELFS Study 1 dataset_unbranded_V10.csv", stringsAsFactors = FALSE)
# List of products in woods
products.keep <-
rbind(woods.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
milk.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
elfs.dat %>% dplyr::select(Department, Aisle, Shelf, product_name = Product)) %>%
unique(.)
dat <-
dat %>%
filter(product_name %in% products.keep$product_name)
nrow(dat)
names(products.keep)
#######
# General purpose of this code is to
# (a) identify individual ingredients within the food products captured by food db
# (b) identify percent composition of the ingredients that have these listed on back of pack labeling
# (c) categorize these ingredients into ~40 categories that pair with Joseph Poore's LCA database
# (d) Repeat part (c) for product names in case products do no have any listed ingredients, or do not have any ingredients with listed % composition
# (e) Merge with LCA database
# (f) Interpolate % composition for ingredients that do not have a % composition listed
# (g) Estimate total impacts per 100g
#######
###
# Loading functions
source("/Volumes/Citadel/Oxford/Research Projects/Categorizations for Marco/Scripts/Functions File Estimating Env Impact of Food Products 7May2020.R")
###
# Importing libraries
library(plyr)
library(dplyr)
library(readr)
library(stringr)
library(stringi)
library(reshape2)
library(dismo)
#####
###
# Importing and managing the data set
dat <-
read_csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/product_data.csv")
# Limiting to products for which I have food categories
# Adding in Woods Data
woods.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database 17December2019.csv", stringsAsFactors = FALSE)
milk.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database milk only 12February2020.csv", stringsAsFactors = FALSE)
elfs.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/ELFS Study 1 dataset_unbranded_V10.csv", stringsAsFactors = FALSE)
# List of products in woods
products.keep <-
rbind(woods.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
milk.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
elfs.dat %>% dplyr::select(Department, Aisle, Shelf, product_name = Product)) %>%
unique(.)
# Removing rows where ingredient text == \\N
# This indicates products that don't contain an ingredients list
# i.e. often "6 Braeburn Apples" or "1kg potatoes"
# Will estimate the impact of these products later
dat <-
dat[dat$ingredients_text != "\\N",]
# Limiting data frame to select columns
# This does not necessarily need to be done, but working on data frames with excess columns annoys me more than it should
dat <-
dplyr::select(dat,
id,
product_name,
ingredients_text) %>%
filter(product_name %in% products.keep$product_name) %>%
left_join(., products.keep %>% unique(.))
loops = length(unique(dat$Department))
loops
departments = sort(unique(dat$Department))
departments
#######
# General purpose of this code is to
# (a) identify individual ingredients within the food products captured by food db
# (b) identify percent composition of the ingredients that have these listed on back of pack labeling
# (c) categorize these ingredients into ~40 categories that pair with Joseph Poore's LCA database
# (d) Repeat part (c) for product names in case products do no have any listed ingredients, or do not have any ingredients with listed % composition
# (e) Merge with LCA database
# (f) Interpolate % composition for ingredients that do not have a % composition listed
# (g) Estimate total impacts per 100g
#######
###
# Loading functions
source("/Volumes/Citadel/Oxford/Research Projects/Categorizations for Marco/Scripts/Functions File Estimating Env Impact of Food Products 7May2020.R")
###
# Importing libraries
library(plyr)
library(dplyr)
library(readr)
library(stringr)
library(stringi)
library(reshape2)
library(dismo)
#####
###
# Importing and managing the data set
dat <-
read_csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/product_data.csv")
# Limiting to products for which I have food categories
# Adding in Woods Data
woods.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database 17December2019.csv", stringsAsFactors = FALSE)
milk.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/woods database milk only 12February2020.csv", stringsAsFactors = FALSE)
elfs.dat <-
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/ELFS Study 1 dataset_unbranded_V10.csv", stringsAsFactors = FALSE)
# List of products in woods
products.keep <-
rbind(woods.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
milk.dat %>% dplyr::select(Department, Aisle, Shelf, product_name),
elfs.dat %>% dplyr::select(Department, Aisle, Shelf, product_name = Product)) %>%
unique(.)
# Removing rows where ingredient text == \\N
# This indicates products that don't contain an ingredients list
# i.e. often "6 Braeburn Apples" or "1kg potatoes"
# Will estimate the impact of these products later
dat <-
dat[dat$ingredients_text != "\\N",]
# Limiting data frame to select columns
# And select products (ones which we can categorize)
# This does not necessarily need to be done, but working on data frames with excess columns annoys me more than it should
dat <-
dplyr::select(dat, # Limiting to select columns
id,
product_name,
ingredients_text) %>%
filter(product_name %in% products.keep$product_name) %>% # Limiting to select products
left_join(., products.keep %>% unique(.)) # Merging in product categories
# Changing semi colons to commas in the ingredient text
# Most products separate individual ingredients by commas, but some use semi colons
# Doing this to be able to run the same code on everything
dat$ingredients_text <-
gsub(";",
",",
dat$ingredients_text)
# Updating "percent" to %
# Doing this to be able to identify percent composition of ingredients later in the text
dat$ingredients_text <-
gsub("percent",
"%",
dat$ingredients_text)
dat$ingredients_text <-
gsub("Percent",
"%",
dat$ingredients_text)
# Allergen advice - this does not indicate any ingredient
dat$ingredients_text <-
gsub("Allergy Advice: For allergens see highlighted ingredients",
"",
dat$ingredients_text)
###
# Converting brackets to parentheses to mesh with rest of script
dat$ingredients_text <-
gsub("\\[|\\{", "(", dat$ingredients_text, perl = TRUE)
dat$ingredients_text <-
gsub("\\]|\\}", ")", dat$ingredients_text, perl = TRUE)
# Managing search words
search.words =
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/Search words 6April2020 try2.csv", stringsAsFactors = FALSE) %>%
mutate(count = NA) %>% # Creating count column
cbind(., # Parsing search words
str_split_fixed(.$Search_Words,"\\|",n = 500))
# Converting to character strings
for(i in which(names(search.words) %in% '1') : which(names(search.words) %in% '500')) {
search.words[,i] <- as.character(search.words[,i])
}
###
# Importing nutrient info
nut.info =
read.csv("/Volumes/Citadel/Oxford/Research Projects/Env and Health Snapshot of FoodDB/Data Inputs/Nutrient Info By LCA Category 24April2020.csv",
stringsAsFactors = FALSE)
#####
###
# Doing this in a series of loops for each department
# Where unknown data is supplemented by known data within the same department
# Number of loops needed to process the data frame
# This is identified based on the number of departments
loops = length(unique(dat$Department))
# Departments
departments = sort(unique(dat$Department))
# Setting max number of embedded strings to extract from ingredients list for each product
# Increase or decrease to extract more or less
extract_embedded = 10
# Empty list used to store products that can't be estimated
filter.out.ids = c()
# And saving data frame
dat.whole = dat
dat = dat.whole[dat.whole$group %in% departments[z],]
z
z = 1
dat = dat.whole[dat.whole$group %in% departments[z],]
dat = dat.whole[dat.whole$Department %in% departments[z],]
departments[z]
rows.loop = which(dat$ingredients_text != '')
###
# Running function to get embedded ingredients list
dat =
embedded.function(dat = dat %>% as.data.frame(), # Data set
num_embedded = extract_embedded, # Max number of embedded ingredients list to extract for each product
ingredient_list = 'ingredients_text', # Name of column containing the ingredients list
rows.loop = rows.loop,  # Which rows from which to extract embedded ingredients lists
embedded = 'keep') # Keep embedded string
###
# Splitting into multiple columns
# Doing first for initial ingredients list
# But will need to do later for each of the substrings
# Keeping first 50 ingredients
dat <-
cbind(dat,
str_split_fixed(dat$ingredients_text_parsed, # Splitting the parsed text
",", # Based on commas
n = 50) %>% as.data.frame())
# The above code creates leveled factors of the individual ingredients
# We don't want this, because it can do weird things in R
# Now converting these columns to character, because these ended up getting converted to factors earlier
# Note that this preserves the digits/text within each column, but removes teh association to underlying numeric values (levels) that unique strings might have
cols.loop =
which(names(dat) %in% 'V1') :
which(names(dat) %in% 'V50')
for(i in cols.loop) {
dat[,i] <- as.character(dat[,i])
}
###
# This doesn't split perfectly (because of added or misplaced characters in the ingredient list)
# So going back and updating these
dat =
corrected.split.function(dat = dat,
cols.loop = cols.loop)
###
# And in some cases, this may still not split perfectly
# This is largely because i.e. there are misplaced "(" or ")"
# These are used to identify the embedded lists
# But if these are misplaced (i.e. there are extra ones or not enough of them)
# Then the embedded lists are not going to be identified perfectly
# So...making a note of these products for data quality purposes later
dat <-
dat %>%
mutate(equal_parentheses = ifelse(str_count(dat$ingredients_text, "\\(") == str_count(dat$ingredients_text,"\\)"),
'Equal',
'Unequal'))
###
# Converting from long to wide
# Instead of having a data frame with 50ish columns, now have a data frame with a few columns but many more rows
dat.long <-
melt(dat[,c(which(names(dat) %in% 'id'),
which(names(dat) %in% 'product_name'),
which(names(dat) %in% 'V1') : which(names(dat) %in% 'V50'))],
id = c('id','product_name')) %>%
left_join(.,
dat %>% dplyr::select(id, product_name, equal_parentheses))
# Getting rid of rows with no identified ingredient
# In other words, if a product has 3 ingredients, there would be 47 rows for that product that contain empty text
# Removing these rows
dat.long <-
dat.long %>%
filter(value != "") %>%
filter(variable != 'ingredients_text')
names(dat.long)
###
# Merging in embedded ingredients lists
# Looping to merge these in
for(i in which(names(dat) %in% 'ing_string1') : which(names(dat) %in% paste0('ing_string',extract_embedded))) {
tmp.df <-
dat[,c(which(names(dat) %in% 'id'),
which(names(dat) %in% 'product_name'),
i,i - extract_embedded)] %>%
mutate(pasted_string = paste0('V',.[,3])) %>%
filter(pasted_string != 'VNA') %>%
mutate(variable = pasted_string)
if(length(-grep("\\b\\([A-z]*\\),\\b",tmp.df[,4])) > 0) {
tmp.df <-
tmp.df[-grep("\\b\\([A-z]*\\),\\b",tmp.df[,4]),]
} else if(length(-grep("\\b\\([A-z]*\\),\\b",tmp.df[,4])) == 0) {
tmp.df <- tmp.df
}
dat.long <-
dat.long %>%
left_join(.,
tmp.df[,c(which(names(tmp.df) %in% 'id'),
which(names(tmp.df) %in% 'product_name'),
which(names(tmp.df) %in% 'variable'),
grep('\\bstring[0-9]{1,2}',names(tmp.df)))])
}
View(dat.long)
###
# Collapsing these strings into a single column
# First need to convert NAs to empty strings
dat.long$embedded_ingredients = ''
for(i in which(names(dat.long) %in% 'string1'): which(names(dat.long) %in% paste0('string',extract_embedded))) {
dat.long[is.na(dat.long[,i]),i] <- ''
dat.long$embedded_ingredients <- paste0(dat.long$embedded_ingredients, dat.long[,i])
}
###
# Sorting df
dat.long$sort <- as.numeric(gsub("V","",dat.long$variable))
dat.long <-
dat.long[order(dat.long$id, dat.long$sort),]
dat.long <- dat.long %>% dplyr::select(-sort)
#####
###
# Identifying % composition as identified in the ingredients list
# Removing commas in ingredient texts
# Doing this helps match percentages later
dat.long <-
percent.composition.function(dat = dat.long,
ingredient.col = 'value',
variable.col = 'variable',
id.var = 'id')
# Filtering products without any percents identified
filter.out =
dat.long %>%
filter(variable %in% c('V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15')) %>%
mutate(count = ifelse(!is.na(percent0),1,0)) %>%
group_by(id, product_name) %>%
summarise(count = sum(count)) %>%
filter(count %in% 0)
filter.out.ids =
c(filter.out.ids,
filter.out$id)
# And updating
dat.long <-
dat.long %>%
filter(!(id %in% filter.out$id)) %>%
mutate(percent0 = gsub("%","", percent0)) %>% # Getting rid of % sign
mutate(percent_0 = ifelse(str_count(embedded_ingredients,",") %in% c(0,1) # identifying percent of ingredients with
& str_count(embedded_ingredients,"%") %in% c(1) # (a) a single comma in embedded ingredients, (b) a single percent in embedded ingredients
& is.na(percent0), # and (c) no percent recognized
str_extract(embedded_ingredients, "[0-9]{1,3}(\\s)?%|[0-9]{1,3}(\\.)[0-9]{1,2}(\\s)?%"),
percent0)) %>%
mutate(percent_0 = gsub("%","",percent_0)) %>%
mutate(percent0 = ifelse(is.na(percent0), percent_0,percent0)) %>%
dplyr::select(-percent_0) %>%
mutate(percent0 = as.numeric(percent0)) %>% # Changing to percent
mutate(percent = percent0) %>% # Adding other columns to mesh with rest of code
mutate(percent_updated = percent)# See above line
###
# And now removing a few characters to avoid complications in the code below
# Removing parentheses to avoid issues matching ingredients
dat.long <-
dat.long %>%
mutate(value = gsub("\\(","",value, perl = TRUE)) %>% # Getting rid of parentheses
mutate(value = gsub("\\)","",value, perl = TRUE)) %>% # Getting rid of parentheses
mutate(value = gsub("%","",value, perl = TRUE)) %>% # Getting rid of percent signs
mutate(value = gsub("Vitamin(\\s)?(B)?[0-9]*","VitaminNUMBER",value,perl=TRUE,ignore.case=TRUE)) %>% # Converting vitamins to NUMBER (i.e. Vitamin B3 = Vitamin BNUMBER)
mutate(value = gsub("[0-9]","",value,perl = TRUE)) %>% # getting rid of any remaining numbers
mutate(value = gsub("[*]","",value, perl = TRUE)) %>% # getting rid of remaining asterisks
mutate(value = trimws(value, which = 'left')) %>% # removing leading white space
mutate(Food_Category = NA)
# Removing leading white space
# This also messes with grepl later
dat.long$value <- trimws(dat.long$value, which = 'left')
###
# For each ingredient, the logic is
# if item has not already been sorted into a category, then search that ingredient for a key word, and update the lca food category with the approriate value
# There are 40ish LCA categories
# LCA categories are rather broad, so the list of search words for these categories can be quite long
# Search goes from least common to most common
dat.long <-
match.ingredient.function(dat = dat.long,
search.words = search.words)
###
# Updating percent for embedded ingredients if only a single percent
# a single ingredient
# and percent of embedded ingredient <= 100/n, where n = nth ingredient in ingredient list
# then repeating if there is only a single embedded ingredient and food category is not identified
dat.long <-
dat.long %>%
mutate(count_percent_embedded = str_count(embedded_ingredients, "%")) %>% # Count of % signs in embedded lists
mutate(count_comma_embedded = str_count(embedded_ingredients, ",")) %>% # Count of commas in embedded lists
mutate(percent_embedded = ifelse(count_percent_embedded %in% 1 & count_comma_embedded %in% 0 & is.na(percent0), # Only identify percent embedded if 1 percent and 0 commas
str_extract(embedded_ingredients,"[0-9]{1,3}(\\s)?%|[0-9]{1,3}(\\.)[0-9]{1,2}(\\s)?%"),
NA)) %>%
mutate(percent_embedded = ifelse(percent_embedded > 100 / as.numeric(gsub("V","",variable)), # Embedded percent cannot be > 100/n
NA,
percent_embedded)) %>%
mutate(percent0 = ifelse(is.na(percent0) & !is.na(percent_embedded), # Updating percent0
percent_embedded,
percent0))
# A bit of data formatting before this
dat.long <-
dat.long %>%
mutate(value = ifelse(is.na(Food_Category) &
!is.na(embedded_ingredients) &
embedded_ingredients != '' &
count_comma_embedded %in% 0,
embedded_ingredients,
value))
# And repeating for these updated values
dat.long <-
match.ingredient.function(dat = dat.long,
search.words = search.words)
###
# Getting list of ingredients that do not match based on the above search words
dat.check <-
dat.long %>%
mutate(count = 1) %>%
filter(is.na(Food_Category)) %>%
group_by(value) %>%
summarise(count = sum(count))
View(dat.check)
View(dat.long)
#####
###
# Next chunk of script gets list of products that didn't have any matched ingredients
# In other words, this is very similar to the above few hundred lines of code
# But runs on products, rather than ingredients
# Searches through the product names of these products
# And tries to sort these products into the LCA food categories
###
# Getting products that don't have any listed food categories
# Getting products without any matched ingredients
# Or where matched ingredients have a summed percent composition of 0
# First setting percent composition of ingredients with a single item to 100
dat.long <-
dat.long %>%
left_join(.,
dat.long %>% mutate(count = 1) %>% group_by(id, product_name) %>% summarise(n_ingredients = sum(count))) %>%
mutate(percent0 = ifelse(n_ingredients %in% 1, 100, percent0)) %>%
mutate(percent0 = gsub("%","",percent0)) %>%
mutate(percent0 = as.numeric(percent0))
dat.long <-
left_join(dat.long,
dat.long %>% group_by(id, product_name) %>% summarise(tot_percent = sum(percent0, na.rm = TRUE)))
test1 <-
dat.long %>%
mutate(count = 1) %>%
mutate(count_variable = 1) %>%
mutate(count = ifelse(is.na(Food_Category),0,count)) %>%
mutate(percent_updated = gsub("%","",percent0)) %>%
mutate(percent_updated = as.numeric(percent_updated)) %>%
group_by(id) %>%
summarise(count = sum(count,na.rm=TRUE), count_variable = sum(count_variable, na.rm = TRUE), percent = sum(percent_updated,na.rm=TRUE))
###
# Getting list of these products
test.products <-
unique(c(test1$id[test1$percent==0],
test1$id[test1$count == 0]))
dat.products <-
dat.long %>%
filter(id %in% test.products) %>%
filter(variable %in% "V1") %>%
mutate(percent0 = 100, tot_percent = 100) %>%
mutate(Food_Category = NA, value = NA) %>%
mutate(Estimated_by_Product_Name = 'Yes')
###
# Have now sorted products into categories
# Dropping other products that cannot be sorting by ingredient list
# And appending these to the ingredient lists
dat.long <-
dat.long %>% filter(!(id %in% dat.products$id))
View(dat.products)
dat.ingredients <-
interpolate.food.ingredients(dat = dat.long)
x
rm(interpolate.food.ingredients())
interpolate
